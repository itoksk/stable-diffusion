#!/usr/bin/env python3
"""
Stable Diffusion ç”»åƒç”Ÿæˆãƒ—ãƒ­ã‚°ãƒ©ãƒ  Version 2
è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰é¸æŠå¯èƒ½ã€å„ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´èª¬æ˜ä»˜ã
"""

from diffusers import StableDiffusionPipeline, StableDiffusionXLPipeline, EulerDiscreteScheduler, DPMSolverMultistepScheduler
from diffusers.models import AutoencoderKL
import torch
import datetime
import os
import random

# åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã®ãƒªã‚¹ãƒˆï¼ˆã™ã¹ã¦ç„¡æ–™ãƒ»å®‰å…¨ï¼‰
MODELS = {
    "1": {
        "name": "Anything V5",
        "id": "stablediffusionapi/anything-v5",
        "type": "SD1.5",
        "vae": "stabilityai/sd-vae-ft-mse",
        "category": "ã‚¢ãƒ‹ãƒ¡ãƒ»ã‚¤ãƒ©ã‚¹ãƒˆ",
        "description": "ä¸‡èƒ½å‹ã‚¢ãƒ‹ãƒ¡ãƒ¢ãƒ‡ãƒ«ã€‚å¹…åºƒã„ã‚¢ãƒ‹ãƒ¡ã‚¹ã‚¿ã‚¤ãƒ«ã«å¯¾å¿œã—ã€åˆå¿ƒè€…ã«ã‚‚ä½¿ã„ã‚„ã™ã„ã€‚",
        "sample_prompts": [
            "1girl, school uniform, cherry blossoms, smile",
            "fantasy knight, armor, castle background",
            "cute cat ears girl, magical girl outfit"
        ]
    },
    "2": {
        "name": "Realistic Vision V6.0",
        "id": "SG161222/Realistic_Vision_V6.0_B1_noVAE",
        "type": "SD1.5",
        "vae": "stabilityai/sd-vae-ft-mse-original",
        "category": "å†™å®Ÿçš„ãƒ»ãƒªã‚¢ãƒ«",
        "description": "æœ€é«˜å³°ã®å†™å®Ÿçš„ãƒ¢ãƒ‡ãƒ«ã€‚äººç‰©ã€å‹•ç‰©ã€é¢¨æ™¯ã™ã¹ã¦ã§ãƒ•ã‚©ãƒˆãƒªã‚¢ãƒ«ãªç”»åƒã‚’ç”Ÿæˆã€‚",
        "sample_prompts": [
            "professional portrait photo of a woman, natural lighting, bokeh",
            "majestic lion in african savanna, golden hour, wildlife photography",
            "modern cityscape at night, neon lights, rain, cinematic"
        ]
    },
    "3": {
        "name": "Counterfeit V3.0",
        "id": "gsdf/Counterfeit-V3.0",
        "type": "SD1.5",
        "vae": "stabilityai/sd-vae-ft-mse",
        "category": "ã‚¢ãƒ‹ãƒ¡ãƒ»ã‚¤ãƒ©ã‚¹ãƒˆ",
        "description": "é«˜å“è³ªãªã‚¢ãƒ‹ãƒ¡ã‚¤ãƒ©ã‚¹ãƒˆç‰¹åŒ–ã€‚ç¹Šç´°ã§ç¾ã—ã„ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¡¨ç¾ãŒå¾—æ„ã€‚",
        "sample_prompts": [
            "1girl, detailed eyes, flowing hair, fantasy dress, magical aura",
            "anime style, vibrant colors, dynamic pose, action scene",
            "kawaii chibi character, pastel colors, heart decorations"
        ]
    },
    "4": {
        "name": "DreamShaper",
        "id": "Lykon/DreamShaper",
        "type": "SD1.5",
        "vae": "stabilityai/sd-vae-ft-mse",
        "category": "ä¸‡èƒ½ãƒ»ã‚¢ãƒ¼ãƒˆ",
        "description": "ãƒªã‚¢ãƒ«ã‹ã‚‰ãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒ¼ã¾ã§å¹…åºƒãå¯¾å¿œã€‚ç‰¹ã«SFãƒ»ã‚µã‚¤ãƒãƒ¼ãƒ‘ãƒ³ã‚¯é¢¨æ™¯ãŒå¾—æ„ã€‚",
        "sample_prompts": [
            "cyberpunk city, neon lights, flying cars, rain",
            "ethereal fantasy landscape, floating islands, magical crystals",
            "steampunk inventor workshop, gears and machinery, vintage"
        ]
    },
    "5": {
        "name": "EpicRealism",
        "id": "emilianJR/epiCRealism",
        "type": "SD1.5",
        "vae": "stabilityai/sd-vae-ft-mse",
        "category": "å†™å®Ÿçš„ãƒ»ãƒªã‚¢ãƒ«",
        "description": "è‡ªç„¶ãªè‚Œã®è³ªæ„Ÿã¨ç…§æ˜ãŒç‰¹å¾´ã€‚äººç‰©å†™çœŸã«æœ€é©ã€‚",
        "sample_prompts": [
            "close-up portrait, natural skin texture, soft lighting",
            "candid street photography, natural expressions, urban setting",
            "fashion photography, elegant dress, studio lighting"
        ]
    }
}

class StableDiffusionGenerator:
    def __init__(self):
        self.pipe = None
        self.current_model = None
        
    def show_model_menu(self):
        """åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚’è¡¨ç¤º"""
        print("\n" + "="*70)
        print("åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ä¸€è¦§")
        print("="*70)
        
        for key, model in MODELS.items():
            print(f"\n[{key}] {model['name']} ({model['category']})")
            print(f"    {model['description']}")
            print(f"    ä¾‹: {model['sample_prompts'][0]}")
        
        print("\n" + "="*70)
        
    def load_model(self, model_key):
        """é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
        if model_key not in MODELS:
            raise ValueError(f"ç„¡åŠ¹ãªãƒ¢ãƒ‡ãƒ«ç•ªå·ã§ã™: {model_key}")
        
        model_info = MODELS[model_key]
        print(f"\n{model_info['name']}ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...")
        
        # VAEã®èª­ã¿è¾¼ã¿
        vae = AutoencoderKL.from_pretrained(model_info['vae'])
        
        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã®è¨­å®š
        if model_info['category'] == "ã‚¢ãƒ‹ãƒ¡ãƒ»ã‚¤ãƒ©ã‚¹ãƒˆ":
            scheduler = EulerDiscreteScheduler.from_pretrained(
                model_info['id'], 
                subfolder="scheduler"
            )
        else:
            scheduler = DPMSolverMultistepScheduler.from_pretrained(
                model_info['id'], 
                subfolder="scheduler"
            )
        
        # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ä½œæˆ
        if model_info['type'] == "SD1.5":
            self.pipe = StableDiffusionPipeline.from_pretrained(
                model_info['id'],
                scheduler=scheduler,
                vae=vae,
                safety_checker=None,
                requires_safety_checker=False,
                custom_pipeline="lpw_stable_diffusion"
            )
        else:  # SDXL
            self.pipe = StableDiffusionXLPipeline.from_pretrained(
                model_info['id'],
                scheduler=scheduler,
                vae=vae,
                use_safetensors=True
            )
        
        # GPUã«è»¢é€
        if torch.cuda.is_available():
            self.pipe = self.pipe.to("cuda")
            print("GPUã‚’ä½¿ç”¨ã—ã¾ã™")
        else:
            print("CPUã‚’ä½¿ç”¨ã—ã¾ã™ï¼ˆç”Ÿæˆã«æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ï¼‰")
            
        self.current_model = model_info
        print(f"{model_info['name']}ã®èª­ã¿è¾¼ã¿ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        
    def generate_image(self, prompt, negative_prompt="", num_images=1, 
                      width=512, height=512, cfg_scale=7, steps=20, seed=-1):
        """ç”»åƒã‚’ç”Ÿæˆ"""
        if self.pipe is None:
            raise RuntimeError("ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
        output_dir = "output"
        os.makedirs(output_dir, exist_ok=True)
        
        print(f"\nç”»åƒã‚’ç”Ÿæˆä¸­...")
        print(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompt}")
        
        generated_images = []
        
        for i in range(num_images):
            # ã‚·ãƒ¼ãƒ‰å€¤ã®è¨­å®š
            if seed == -1:
                current_seed = random.randint(0, 2147483647)
            else:
                current_seed = seed + i
                
            generator = torch.Generator(device="cuda" if torch.cuda.is_available() else "cpu")
            generator.manual_seed(current_seed)
            
            # ç”»åƒç”Ÿæˆ
            image = self.pipe(
                prompt=prompt,
                negative_prompt=negative_prompt,
                width=width,
                height=height,
                generator=generator,
                guidance_scale=cfg_scale,
                num_inference_steps=steps
            ).images[0]
            
            # ãƒ•ã‚¡ã‚¤ãƒ«åã®ç”Ÿæˆ
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"{self.current_model['name'].replace(' ', '_')}_{timestamp}_{current_seed}.png"
            filepath = os.path.join(output_dir, filename)
            
            # ç”»åƒã‚’ä¿å­˜
            image.save(filepath)
            generated_images.append(filepath)
            print(f"ç”»åƒã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filepath}")
            
        return generated_images

def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚°ãƒ©ãƒ """
    print("\nğŸ¨ Stable Diffusion ç”»åƒç”Ÿæˆãƒ—ãƒ­ã‚°ãƒ©ãƒ  Version 2")
    print("è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰é¸æŠã—ã¦ç”»åƒã‚’ç”Ÿæˆã§ãã¾ã™")
    
    generator = StableDiffusionGenerator()
    
    while True:
        # ãƒ¢ãƒ‡ãƒ«é¸æŠ
        generator.show_model_menu()
        model_choice = input("\nãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„ (ç•ªå·ã‚’å…¥åŠ›): ")
        
        try:
            generator.load_model(model_choice)
        except Exception as e:
            print(f"ã‚¨ãƒ©ãƒ¼: {e}")
            continue
            
        # ã‚µãƒ³ãƒ—ãƒ«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è¡¨ç¤º
        model_info = MODELS[model_choice]
        print(f"\nğŸ’¡ {model_info['name']}ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:")
        for i, prompt in enumerate(model_info['sample_prompts'], 1):
            print(f"   {i}. {prompt}")
        
        # ç”»åƒç”Ÿæˆãƒ«ãƒ¼ãƒ—
        while True:
            print("\n" + "-"*50)
            prompt = input("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ› (qã§ãƒ¢ãƒ‡ãƒ«é¸æŠã«æˆ»ã‚‹): ")
            
            if prompt.lower() == 'q':
                break
                
            # è©³ç´°è¨­å®š
            use_default = input("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™ã‹ï¼Ÿ (y/n): ").lower() == 'y'
            
            if use_default:
                negative_prompt = "nsfw, low quality, blurry" if model_info['category'] == "å†™å®Ÿçš„ãƒ»ãƒªã‚¢ãƒ«" else "nsfw"
                num_images = 1
                width = 512
                height = 512
                cfg_scale = 7
                steps = 20
                seed = -1
            else:
                negative_prompt = input("ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ (Enter ã§ã‚¹ã‚­ãƒƒãƒ—): ")
                num_images = int(input("ç”Ÿæˆæšæ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1): ") or "1")
                width = int(input("ç”»åƒã®å¹… (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 512): ") or "512")
                height = int(input("ç”»åƒã®é«˜ã• (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 512): ") or "512")
                cfg_scale = float(input("CFG Scale (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 7): ") or "7")
                steps = int(input("ã‚¹ãƒ†ãƒƒãƒ—æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 20): ") or "20")
                seed = int(input("ã‚·ãƒ¼ãƒ‰å€¤ (-1ã§ãƒ©ãƒ³ãƒ€ãƒ ): ") or "-1")
            
            try:
                # ç”»åƒç”Ÿæˆ
                generated_files = generator.generate_image(
                    prompt=prompt,
                    negative_prompt=negative_prompt,
                    num_images=num_images,
                    width=width,
                    height=height,
                    cfg_scale=cfg_scale,
                    steps=steps,
                    seed=seed
                )
                
                print(f"\nâœ… {len(generated_files)}æšã®ç”»åƒã‚’ç”Ÿæˆã—ã¾ã—ãŸï¼")
                
            except Exception as e:
                print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                
        # åˆ¥ã®ãƒ¢ãƒ‡ãƒ«ã‚’è©¦ã™ã‹ç¢ºèª
        if input("\nåˆ¥ã®ãƒ¢ãƒ‡ãƒ«ã‚’è©¦ã—ã¾ã™ã‹ï¼Ÿ (y/n): ").lower() != 'y':
            break
    
    print("\nğŸ‘‹ ã”åˆ©ç”¨ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸï¼")

if __name__ == "__main__":
    main()