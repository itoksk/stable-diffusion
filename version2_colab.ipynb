{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stable Diffusion Version 2 - è¤‡æ•°ãƒ¢ãƒ‡ãƒ«é¸æŠå‹\n",
    "ç„¡æ–™ã§å®‰å…¨ãª5ã¤ã®ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰é¸ã‚“ã§ç”»åƒç”Ÿæˆã§ãã¾ã™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ã‚»ãƒ«â‘  å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
    "!pip install --upgrade diffusers[torch] transformers accelerate -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title ã‚»ãƒ«â‘¢ ãƒ¢ãƒ‡ãƒ«ã®é¸æŠã¨èª­ã¿è¾¼ã¿\n\nfrom diffusers import StableDiffusionPipeline, EulerDiscreteScheduler, DPMSolverMultistepScheduler\nfrom diffusers.models import AutoencoderKL\nimport torch\n\n# ãƒ¢ãƒ‡ãƒ«é¸æŠ\nselected_model = \"Anything V5 (ã‚¢ãƒ‹ãƒ¡)\" #@param [\"Anything V5 (ã‚¢ãƒ‹ãƒ¡)\", \"Realistic Vision V6.0 (å†™å®Ÿçš„)\", \"Counterfeit V3.0 (ã‚¢ãƒ‹ãƒ¡)\", \"DreamShaper (ä¸‡èƒ½)\", \"EpicRealism (å†™å®Ÿçš„)\"]\n\nmodel_info = MODELS[selected_model]\nprint(f\"\\né¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«: {selected_model}\")\nprint(f\"èª¬æ˜: {model_info['description']}\")\nprint(f\"\\nãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...\")\n\n# VAEã®èª­ã¿è¾¼ã¿\ntry:\n    vae = AutoencoderKL.from_pretrained(model_info['vae'])\nexcept Exception as e:\n    print(f\"æŒ‡å®šã•ã‚ŒãŸVAEã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}\")\n    print(\"ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆVAEã‚’ä½¿ç”¨ã—ã¾ã™\")\n    vae = None\n\n# ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã®è¨­å®šï¼ˆã‚¢ãƒ‹ãƒ¡ç³»ã¯Eulerã€ãƒªã‚¢ãƒ«ç³»ã¯DPMï¼‰\ntry:\n    if \"ã‚¢ãƒ‹ãƒ¡\" in selected_model:\n        scheduler = EulerDiscreteScheduler.from_pretrained(model_info['id'], subfolder=\"scheduler\")\n    else:\n        scheduler = DPMSolverMultistepScheduler.from_pretrained(model_info['id'], subfolder=\"scheduler\")\nexcept Exception as e:\n    print(f\"ã‚«ã‚¹ã‚¿ãƒ ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}\")\n    print(\"ãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚’ä½¿ç”¨ã—ã¾ã™\")\n    scheduler = None\n\n# ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ä½œæˆ\ntry:\n    # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ãŒã‚ã‚‹å ´åˆã¯æŒ‡å®šã€ãªã„å ´åˆã¯ãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’ä½¿ç”¨\n    pipeline_kwargs = {\n        \"safety_checker\": None,\n        \"requires_safety_checker\": False,\n        \"torch_dtype\": torch.float16\n    }\n    \n    if scheduler is not None:\n        pipeline_kwargs[\"scheduler\"] = scheduler\n    if vae is not None:\n        pipeline_kwargs[\"vae\"] = vae\n    \n    # ã¾ãšã‚«ã‚¹ã‚¿ãƒ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§è©¦ã™\n    try:\n        pipe = StableDiffusionPipeline.from_pretrained(\n            model_info['id'],\n            custom_pipeline=\"lpw_stable_diffusion\",\n            **pipeline_kwargs\n        )\n        print(\"ã‚«ã‚¹ã‚¿ãƒ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆlpw_stable_diffusionï¼‰ã‚’ä½¿ç”¨\")\n    except:\n        # æ¨™æº–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§è©¦ã™\n        pipe = StableDiffusionPipeline.from_pretrained(\n            model_info['id'],\n            **pipeline_kwargs\n        )\n        print(\"æ¨™æº–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½¿ç”¨\")\n        \nexcept Exception as e:\n    print(f\"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}\")\n    raise e\n\npipe = pipe.to(\"cuda\")\nprint(f\"\\nâœ… {selected_model}ã®èª­ã¿è¾¼ã¿ãŒå®Œäº†ã—ã¾ã—ãŸï¼\")\nprint(f\"\\nğŸ’¡ ã‚µãƒ³ãƒ—ãƒ«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {model_info['sample']}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ã‚»ãƒ«â‘¢ ãƒ¢ãƒ‡ãƒ«ã®é¸æŠã¨èª­ã¿è¾¼ã¿\n",
    "\n",
    "from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler, DPMSolverMultistepScheduler\n",
    "from diffusers.models import AutoencoderKL\n",
    "import torch\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«é¸æŠ\n",
    "selected_model = \"Anything V5 (ã‚¢ãƒ‹ãƒ¡)\" #@param [\"Anything V5 (ã‚¢ãƒ‹ãƒ¡)\", \"Realistic Vision V6.0 (å†™å®Ÿçš„)\", \"Counterfeit V3.0 (ã‚¢ãƒ‹ãƒ¡)\", \"DreamShaper (ä¸‡èƒ½)\", \"EpicRealism (å†™å®Ÿçš„)\"]\n",
    "\n",
    "model_info = MODELS[selected_model]\n",
    "print(f\"\\né¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«: {selected_model}\")\n",
    "print(f\"èª¬æ˜: {model_info['description']}\")\n",
    "print(f\"\\nãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...\")\n",
    "\n",
    "# VAEã®èª­ã¿è¾¼ã¿\n",
    "vae = AutoencoderKL.from_pretrained(model_info['vae'])\n",
    "\n",
    "# ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã®è¨­å®šï¼ˆã‚¢ãƒ‹ãƒ¡ç³»ã¯Eulerã€ãƒªã‚¢ãƒ«ç³»ã¯DPMï¼‰\n",
    "if \"ã‚¢ãƒ‹ãƒ¡\" in selected_model:\n",
    "    scheduler = EulerDiscreteScheduler.from_pretrained(model_info['id'], subfolder=\"scheduler\")\n",
    "else:\n",
    "    scheduler = DPMSolverMultistepScheduler.from_pretrained(model_info['id'], subfolder=\"scheduler\")\n",
    "\n",
    "# ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ä½œæˆ\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    model_info['id'],\n",
    "    scheduler=scheduler,\n",
    "    vae=vae,\n",
    "    safety_checker=None,\n",
    "    requires_safety_checker=False,\n",
    "    custom_pipeline=\"lpw_stable_diffusion\"\n",
    ")\n",
    "\n",
    "pipe = pipe.to(\"cuda\")\n",
    "print(f\"\\nâœ… {selected_model}ã®èª­ã¿è¾¼ã¿ãŒå®Œäº†ã—ã¾ã—ãŸï¼\")\n",
    "print(f\"\\nğŸ’¡ ã‚µãƒ³ãƒ—ãƒ«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {model_info['sample']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ã‚»ãƒ«â‘£ ç”»åƒç”Ÿæˆ\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import random\n",
    "from IPython.display import display, Image as IPImage\n",
    "\n",
    "# å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ã®ä½œæˆ\n",
    "!mkdir -p /content/output\n",
    "\n",
    "# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š\n",
    "prompt = \"masterpiece, best quality, 1girl, japanese school uniform, cherry blossoms, spring, smile\" #@param {type:\"string\"}\n",
    "negative_prompt = \"nsfw, low quality, blurry, bad anatomy\" #@param {type:\"string\"}\n",
    "num_images = 2 #@param {type:\"slider\", min:1, max:4, step:1}\n",
    "width = 512 #@param {type:\"slider\", min:256, max:1024, step:64}\n",
    "height = 768 #@param {type:\"slider\", min:256, max:1024, step:64}\n",
    "cfg_scale = 7 #@param {type:\"slider\", min:1, max:20, step:0.5}\n",
    "steps = 25 #@param {type:\"slider\", min:10, max:50, step:5}\n",
    "seed = -1 #@param {type:\"number\"}\n",
    "\n",
    "print(f\"ğŸ¨ ç”»åƒã‚’ç”Ÿæˆä¸­...\")\n",
    "print(f\"ãƒ¢ãƒ‡ãƒ«: {selected_model}\")\n",
    "print(f\"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompt}\")\n",
    "print(f\"ã‚µã‚¤ã‚º: {width}x{height}\")\n",
    "print(f\"ç”Ÿæˆæšæ•°: {num_images}æš\\n\")\n",
    "\n",
    "generated_files = []\n",
    "\n",
    "for i in range(num_images):\n",
    "    # ã‚·ãƒ¼ãƒ‰å€¤ã®è¨­å®š\n",
    "    if seed == -1:\n",
    "        current_seed = random.randint(0, 2147483647)\n",
    "    else:\n",
    "        current_seed = seed + i\n",
    "    \n",
    "    generator = torch.Generator(device=\"cuda\").manual_seed(current_seed)\n",
    "    \n",
    "    # ç”»åƒç”Ÿæˆ\n",
    "    image = pipe(\n",
    "        prompt=prompt,\n",
    "        negative_prompt=negative_prompt,\n",
    "        width=width,\n",
    "        height=height,\n",
    "        generator=generator,\n",
    "        guidance_scale=cfg_scale,\n",
    "        num_inference_steps=steps\n",
    "    ).images[0]\n",
    "    \n",
    "    # ãƒ•ã‚¡ã‚¤ãƒ«åã®ç”Ÿæˆ\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_name = selected_model.split(\" \")[0].replace(\"/\", \"_\")\n",
    "    filename = f\"{model_name}_{timestamp}_{current_seed}.png\"\n",
    "    filepath = f\"/content/output/{filename}\"\n",
    "    \n",
    "    # ç”»åƒã‚’ä¿å­˜\n",
    "    image.save(filepath)\n",
    "    generated_files.append(filepath)\n",
    "    \n",
    "    print(f\"âœ… ç”»åƒ {i+1}/{num_images} ã‚’ç”Ÿæˆã—ã¾ã—ãŸ (seed: {current_seed})\")\n",
    "    \n",
    "    # ç”»åƒã‚’è¡¨ç¤º\n",
    "    display(image)\n",
    "\n",
    "print(f\"\\nğŸ‰ ã™ã¹ã¦ã®ç”»åƒã®ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼\")\n",
    "print(f\"ä¿å­˜å…ˆ: /content/output/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ã‚»ãƒ«â‘¤ ç”Ÿæˆã—ãŸç”»åƒã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰\n",
    "\n",
    "# ZIPãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "!cd /content && zip -r generated_images.zip output/\n",
    "\n",
    "from google.colab import files\n",
    "files.download('/content/generated_images.zip')\n",
    "\n",
    "print(\"âœ… generated_images.zip ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’é–‹å§‹ã—ã¾ã—ãŸ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ ä½¿ã„æ–¹ã®ãƒ’ãƒ³ãƒˆ\n",
    "\n",
    "### ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ›¸ãæ–¹\n",
    "\n",
    "**ã‚¢ãƒ‹ãƒ¡ç³»ãƒ¢ãƒ‡ãƒ«ï¼ˆAnything V5, Counterfeit V3.0ï¼‰**\n",
    "- åŸºæœ¬æ§‹é€ : `masterpiece, best quality, 1girl/1boy, [ç‰¹å¾´], [æœè£…], [èƒŒæ™¯], [ãƒãƒ¼ã‚º/è¡¨æƒ…]`\n",
    "- ä¾‹: `masterpiece, best quality, 1girl, long hair, school uniform, classroom, smile`\n",
    "\n",
    "**ãƒªã‚¢ãƒ«ç³»ãƒ¢ãƒ‡ãƒ«ï¼ˆRealistic Vision, EpicRealismï¼‰**\n",
    "- åŸºæœ¬æ§‹é€ : `[æ’®å½±ã‚¹ã‚¿ã‚¤ãƒ«], [è¢«å†™ä½“], [ç…§æ˜], [æ§‹å›³], [ã‚«ãƒ¡ãƒ©è¨­å®š]`\n",
    "- ä¾‹: `professional portrait photography, young woman, natural lighting, close-up, bokeh background`\n",
    "\n",
    "**ä¸‡èƒ½ç³»ãƒ¢ãƒ‡ãƒ«ï¼ˆDreamShaperï¼‰**\n",
    "- ãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒ¼: `fantasy landscape, floating islands, magical crystals, ethereal atmosphere`\n",
    "- SF: `cyberpunk city, neon lights, rain, night scene, futuristic`\n",
    "\n",
    "### æ¨å¥¨è¨­å®š\n",
    "\n",
    "- **CFG Scale**: \n",
    "  - ã‚¢ãƒ‹ãƒ¡ç³»: 7-10\n",
    "  - ãƒªã‚¢ãƒ«ç³»: 5-8\n",
    "  - ä¸‡èƒ½ç³»: 6-9\n",
    "\n",
    "- **ã‚¹ãƒ†ãƒƒãƒ—æ•°**: \n",
    "  - é«˜é€Ÿç”Ÿæˆ: 20-25\n",
    "  - é«˜å“è³ª: 30-40\n",
    "\n",
    "- **è§£åƒåº¦**:\n",
    "  - ãƒãƒ¼ãƒˆãƒ¬ãƒ¼ãƒˆ: 512x768\n",
    "  - æ¨ªé•·: 768x512\n",
    "  - æ­£æ–¹å½¢: 512x512 or 768x768"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}